{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2p64RQtuNqkmeQZaV5VBl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jasper-Hewitt/social_media/blob/main/twitterapi_long.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "0lVCM6Gb06AL",
        "outputId": "cc1619a0-8f11-432b-fd92-4ab2cb0718d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mood: you are feeling really worried\n",
            "Username: SiemensGamesa\n",
            "prompt: Generate a short tweet (no longer than 180 characters including\n",
            "          whitespaces) that responds to the following tweet, tag the original poster in your response, do not just \n",
            "          simply rephrase the post but add a personal opinion. Never mention that you are an AI. Tweet:\n",
            "@iberdrola üëè\n",
            "yes\n",
            ".Thanks for setting ambitious renewable energy targets! As someone worried about our planet's future, I'm hopeful companies like you will lead the way. #sustainability #climatechange https://twitter.com/SiemensGamesa/status/1659175560768106497\n",
            "output too long, creating shorter version\n",
            "Tweeted: .Thanks for leading the way on renewable energy targets! Your ambition gives me hope for our planet's future.‚Ä¶ https://t.co/G4KhaUwPTD\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-aaf1dc392193>\u001b[0m in \u001b[0;36m<cell line: 208>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m \u001b[0mrun_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-aaf1dc392193>\u001b[0m in \u001b[0;36mrun_scheduler\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mschedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pending\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0mrun_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#________________________________________________________________________________________________\n",
        "\n",
        "#install packages and insert keys\n",
        "# !pip install fitz\n",
        "# !pip install static\n",
        "# !pip install frontend\n",
        "# !pip install pymupdf --upgrade\n",
        "# !pip install openai\n",
        "# !pip install schedule\n",
        "import os\n",
        "import openai\n",
        "import json\n",
        "import schedule\n",
        "import time\n",
        "import random\n",
        "import tweepy\n",
        "\n",
        "#open ai key\n",
        "openai.api_key = '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' #delete when uploading \n",
        "\n",
        "# Authenticate to Twitter\n",
        "auth = tweepy.OAuthHandler(\"OqVsti1iKWNbP7Wb5JN9zaWaI\", 'WOTMyYFsupcnkUrMcLmVXRVXap4PNF5sINL35lNZFstux2pbdQ') #owen consumer keys\n",
        "auth.set_access_token(\"1656141039797940224-y96eF27lVziqkUn6CYULmh2uaDItoV\", 'Kk3irUiecI0Z1m4b7i2VpBEibrjmMBbXh00yvu1OItwi1') #ESGGUardian specific access keys received through authentication\n",
        "\n",
        "# Create API object\n",
        "api = tweepy.API(auth, wait_on_rate_limit=True)#,\n",
        "#    wait_on_rate_limit_notify=True)\n",
        "#_________________________________________________________________________________________________\n",
        "\n",
        "#set up moods and usernames which will be iteratred through randomly\n",
        "moods=['you are feeling really excited', \n",
        "       'you are feeling really frustrated but polite', \n",
        "       'you are feeling really inspired', \n",
        "       'you are feeling really worried', \n",
        "       'you are feeling really Happy']\n",
        "\n",
        "usernames = [\"algore\", \"mtbarra\", \"CFigueres\",\"MarkJCarney\",\"lizwathuti\",\"Hughcevans\",\"SophiaKianni\",\"JeromeFosterII\", \"climatefinance\",\n",
        "             \"dieterholger\",\"CNBCFuture\",\"guardianeco\",\"CarbonBrief\",\"lisapjackson\",\"makower\",\"PaulPolman\",\"DaveStangis\",\"briantippens\",\"KaraHurst\",\"KateEBrandt\",#added later\n",
        "             \"sciencetargets\", \"UNFCCC\", \"EUClimateAction\", \"EsgToday\", 'Vestas', 'SiemensGamesa', 'REWorld', 'Shell', 'exxonmobil', 'generalelectric', 'Microsoft', 'Apple',\n",
        "             \"TataSteelLtd\", 'teslaenergy', 'woodhaus2']\n",
        "\n",
        "\n",
        "prompts=['''Generate a short tweet (no longer than 180 characters including\n",
        "          whitespaces) that responds to the following tweet, tag the original poster in your response, do not just \n",
        "          simply rephrase the post but add a personal opinion. Never mention that you are an AI. Tweet:''',\n",
        "\n",
        "          '''and you are a professional ESG advocate who deeply believes technology can make the world better. \n",
        "            Write a tweet in response to the following tweet. Include the original poster in your post. The tweet can be no \n",
        "            longer than 150 characters, this is a hard limit. Briefly mention a closely related specific technological development \n",
        "            that may support your view. This have to be specific, so do not simply\n",
        "            mention some buzzwords. If there is no closely related piece of technology that can be used to solve this problem, don't mention it. \n",
        "            Never mention that you are an AI. your tweet will be useless if it\n",
        "            is too long so strictly stick to the word limit, never go over it! Tweet:''']\n",
        "#_________________________________________________________________________________________________\n",
        "#get get rid of unwanted stuff \n",
        "import re\n",
        "\n",
        "def remove_unwanted_patterns(text):\n",
        "    patterns = [\n",
        "        r'\\b(?:as an? AI)\\b', # \"as an AI\" or \"as a AI\"\n",
        "        r\"\\b(?:I'm an? AI)\\b\", # \"I'm an AI\" or \"I'm a AI\"\n",
        "        r\"\\b(?:I am an? AI)\\b\"  # \"I am an AI\" or \"I am a AI\"\n",
        "    ]\n",
        "    for pattern in patterns:\n",
        "        text = re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
        "    return text\n",
        "\n",
        "\n",
        "def process_tweet():\n",
        "  mood = random.choice(moods)\n",
        "  username = random.choice(usernames)\n",
        "  prompt=random.choice(prompts)\n",
        "\n",
        "  print(\"Mood:\", mood)\n",
        "  print(\"Username:\", username)\n",
        "  print('prompt:', prompt)\n",
        "\n",
        "  # Get up to 5 of the most recent tweets and make sure they are not retweets\n",
        "  tweets = api.user_timeline(screen_name=username, count=5, tweet_mode='extended', include_rts=False)\n",
        "\n",
        "  # Initialize variables to hold the latest tweet and ID\n",
        "  latest_tweet = None\n",
        "  tweet_id = None\n",
        "\n",
        "  # Loop through the tweets to find one that IS NOT a retweet\n",
        "  # according to some sources, the include_rts=False argument is not sufficient to completely\n",
        "  #block out all of the retweets. \n",
        "  for tweet in tweets:\n",
        "      # If the tweet is not a retweet, store its text and ID and break the loop\n",
        "      if not hasattr(tweet, 'retweeted_status'):\n",
        "        latest_tweet = tweet.full_text\n",
        "        tweet_id = tweet.id_str\n",
        "        break\n",
        "\n",
        "# If no suitable tweet was found, re-run the process_tweet function\n",
        "  if latest_tweet is None or tweet_id is None:\n",
        "      process_tweet()\n",
        "      return\n",
        "  print(latest_tweet)\n",
        "\n",
        "  #process tweet\n",
        "  latest_tweet = '@'+username + ':'+ latest_tweet\n",
        "\n",
        "  #use GPT to verify if the tweet is appropriate\n",
        "  input='''you are a professional ESG PR person that responds to other KOLs' tweets, you will first have to assess whether the following\n",
        "           tweet is appropriate to respond to. you will respond to any tweets that have something to do with ESG developments in the broad sense.\n",
        "           You will not respond to personal statements like 'Im going to LA, let me know if you are there', 'happy birthday to my little kid', \n",
        "           or a tweet that has no clear subject. \n",
        "           is the following tweet appropriate or not? reply with yes or no, nothing else, do not add a period behind the output'''+ latest_tweet\n",
        "\n",
        "  completion = openai.ChatCompletion.create(\n",
        "      model='gpt-3.5-turbo', \n",
        "      messages=[{\"role\": \"user\", \"content\": input}]\n",
        "  )\n",
        "  json_object = json.loads(str(completion))\n",
        "  output = json_object['choices'][0]['message']['content']\n",
        "  output = json_object['choices'][0]['message']['content'].lower() #get rid of variations in the answer\n",
        "  print(output)\n",
        "\n",
        "#________________________________________________________________________________________\n",
        "\n",
        "#big if statement, if tweet is a proper tweet to respond to \n",
        "  if 'yes' in output:\n",
        "    #create response\n",
        "    input=mood + prompt + latest_tweet #'you are feeling really'+ mood +'''Generate a short tweet (no longer than 200 characters including\n",
        "    # whitespaces) that responds to the following tweet, tag the original poster in your response, do not just \n",
        "    # simply rephrase the post but add a personal opinion.'''  + latest_tweet\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "      model=\"gpt-3.5-turbo\", \n",
        "      messages=[{\"role\": \"user\", \"content\": input}]\n",
        "    )\n",
        "    json_object = json.loads(str(completion))\n",
        "    output = json_object['choices'][0]['message']['content']\n",
        "    # print(output)\n",
        "    \n",
        "    # get link \n",
        "    tweet_id = tweet_id # replace with the tweet ID you want to get the link from\n",
        "    screen_name = username # replace with the screen name of the user who posted the tweet\n",
        "\n",
        "    tweet_link = f\"https://twitter.com/{screen_name}/status/{tweet_id}\"\n",
        "\n",
        "    # print(tweet_link)\n",
        "\n",
        "    #gpt4 api? or not necessary?\n",
        "    output='.'+output+' '+ tweet_link\n",
        "    print(output)\n",
        "\n",
        "    # Check the tweet length. If it is more than 230 characters, generate a shorter tweet RECENTLY ADDED!\n",
        "    if len(output) > 230:\n",
        "        print('output too long, creating shorter version')\n",
        "      # Create a new input message with a request for a shorter tweet\n",
        "        input = output + \" Please generate a shorter tweet that is no more than 170 characters. keep the tag and the link because you are still responding to a person\"\n",
        "        completion = openai.ChatCompletion.create(\n",
        "          model=\"gpt-3.5-turbo\", \n",
        "          messages=[{\"role\": \"user\", \"content\": input}]\n",
        "        )\n",
        "        json_object = json.loads(str(completion))\n",
        "        output = json_object['choices'][0]['message']['content']\n",
        "        output = '.'+output\n",
        "\n",
        "     #if it is still too long, start over. Use return so that it doesn't tweet twice (in case it has two tweets of valid length) \n",
        "    if len(output) >230:\n",
        "      print('tweet STILL too long, starting over')\n",
        "      return process_tweet()\n",
        "    \n",
        "    #delete lines like, as an AI, or I'm an AI \n",
        "    output = remove_unwanted_patterns(output)\n",
        "#    print(output)\n",
        "    tweet = api.update_status(output)\n",
        "    print(f\"Tweeted: {tweet.text}\")\n",
        "\n",
        "  #if this is not an appropriate tweet to respond to, restart the process  \n",
        "  elif output == 'no':\n",
        "        process_tweet()\n",
        "  else:\n",
        "        process_tweet()\n",
        "process_tweet()\n",
        "\n",
        "#end of process_tweet() function\n",
        "#________________________________________________________________________________________\n",
        "\n",
        "#start scheduler function! We want it to post twice per day\n",
        "def run_scheduler():\n",
        "    # Clear out existing schedule (optional)\n",
        "    schedule.clear()\n",
        "\n",
        "    # Define the times you want to run the job\n",
        "    morning_hours = list(range(6, 12))  # 6AM - 11AM\n",
        "    afternoon_hours = list(range(12, 18))  # 12PM - 5PM\n",
        "\n",
        "    # Select a random hour in the morning and afternoon\n",
        "    morning_hour = random.choice(morning_hours)\n",
        "    afternoon_hour = random.choice(afternoon_hours)\n",
        "\n",
        "    # Define a random minute\n",
        "    minute = random.randint(0, 59)\n",
        "\n",
        "    # Schedule the job for these times\n",
        "    schedule.every().day.at(f\"{morning_hour:02d}:{minute:02d}\").do(process_tweet)\n",
        "    schedule.every().day.at(f\"{afternoon_hour:02d}:{minute:02d}\").do(process_tweet)\n",
        "\n",
        "    # Keep the script running\n",
        "    while True:\n",
        "        schedule.run_pending()\n",
        "        time.sleep(10)\n",
        "\n",
        "run_scheduler()"
      ]
    }
  ]
}