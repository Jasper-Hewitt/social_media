{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMNwkDo30M/IUTUxTo70Fx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jasper-Hewitt/social_media/blob/main/twitterapi_long.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "0lVCM6Gb06AL",
        "outputId": "4ba2c193-aaf0-4908-f1c5-d0938d2fca5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mood: skeptical\n",
            "Username: lisapjackson\n",
            "So proud of our teams for continuing to make technology more accessible for everyone. https://t.co/8wWZKy9Stb\n",
            "no.\n",
            "Mood: skeptical\n",
            "Username: briantippens\n",
            "We had an amazing time at @Cisco Magnetic ASPIRE at @Nasdaq in NYC tonight ! https://t.co/oSG0eAMZxC\n",
            "no.\n",
            "Mood: Inspired\n",
            "Username: makower\n",
            "This is a critical issue that needs broad attention — and action! Thanks, @SenWhitehouse and @BillWeihl for your leadership on this issue. https://t.co/gEfATaAyBu\n",
            "yes\n",
            "Tweeted: .@makower Thank you for shedding light on such an important issue. It takes leaders like @SenWhitehouse and… https://t.co/4cGcXFpiXh\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-34ba22d3e915>\u001b[0m in \u001b[0;36m<cell line: 166>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m \u001b[0mrun_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-34ba22d3e915>\u001b[0m in \u001b[0;36mrun_scheduler\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mschedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pending\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0mrun_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#________________________________________________________________________________________________\n",
        "\n",
        "#install packages and insert keys\n",
        "!pip install fitz\n",
        "!pip install static\n",
        "!pip install frontend\n",
        "!pip install pymupdf --upgrade\n",
        "!pip install openai\n",
        "!pip install schedule\n",
        "import os\n",
        "import openai\n",
        "import json\n",
        "import schedule\n",
        "import time\n",
        "import random\n",
        "import tweepy\n",
        "\n",
        "#open ai key\n",
        "openai.api_key = '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' #delete when uploading \n",
        "\n",
        "# Authenticate to Twitter\n",
        "auth = tweepy.OAuthHandler(\"OqVsti1iKWNbP7Wb5JN9zaWaI\", 'WOTMyYFsupcnkUrMcLmVXRVXap4PNF5sINL35lNZFstux2pbdQ') #owen consumer keys\n",
        "auth.set_access_token(\"1656141039797940224-y96eF27lVziqkUn6CYULmh2uaDItoV\", 'Kk3irUiecI0Z1m4b7i2VpBEibrjmMBbXh00yvu1OItwi1') #ESGGUardian specific access keys received through authentication\n",
        "\n",
        "# Create API object\n",
        "api = tweepy.API(auth, wait_on_rate_limit=True)#,\n",
        "#    wait_on_rate_limit_notify=True)\n",
        "#_________________________________________________________________________________________________\n",
        "\n",
        "#set up moods and usernames which will be iteratred through randomly\n",
        "moods=['Excited', 'Frustrated but polite', 'Inspired', 'worried', 'Happy', 'skeptical']\n",
        "usernames = [\n",
        "    \"algore\",\n",
        "    \"mtbarra\",\n",
        "    \"CFigueres\",\n",
        "    \"MarkJCarney\",\n",
        "    \"lizwathuti\",\n",
        "    \"Hughcevans\",\n",
        "    \"SophiaKianni\",\n",
        "    \"JeromeFosterII\",\n",
        "    \"climatefinance\",\n",
        "    \"dieterholger\",\n",
        "    \"CNBCFuture\",\n",
        "    \"guardianeco\",\n",
        "    \"CarbonBrief\",\n",
        "    \"lisapjackson\",\n",
        "    \"makower\",\n",
        "    \"PaulPolman\",\n",
        "    \"DaveStangis\",\n",
        "    \"briantippens\",\n",
        "    \"KaraHurst\",\n",
        "    \"KateEBrandt\"\n",
        "]\n",
        "#_________________________________________________________________________________________________\n",
        "\n",
        "def process_tweet():\n",
        "  mood = random.choice(moods)\n",
        "  username = random.choice(usernames)\n",
        "\n",
        "  print(\"Mood:\", mood)\n",
        "  print(\"Username:\", username)\n",
        "\n",
        "  # Get up to 5 of the most recent tweets and make sure they are not retweets\n",
        "  tweets = api.user_timeline(screen_name=username, count=5, tweet_mode='extended', include_rts=False)\n",
        "\n",
        "  # Initialize variables to hold the latest tweet and ID\n",
        "  latest_tweet = None\n",
        "  tweet_id = None\n",
        "\n",
        "  # Loop through the tweets to find one that IS NOT a retweet\n",
        "  # according to some sources, the include_rts=False argument is not sufficient to completely\n",
        "  #block out all of the retweets. \n",
        "  for tweet in tweets:\n",
        "      # If the tweet is not a retweet, store its text and ID and break the loop\n",
        "      if not hasattr(tweet, 'retweeted_status'):\n",
        "        latest_tweet = tweet.full_text\n",
        "        tweet_id = tweet.id_str\n",
        "        break\n",
        "\n",
        "# If no suitable tweet was found, re-run the process_tweet function\n",
        "  if latest_tweet is None or tweet_id is None:\n",
        "      process_tweet()\n",
        "      return\n",
        "  print(latest_tweet)\n",
        "\n",
        "  #process tweet\n",
        "  latest_tweet = '@'+username + ':'+ latest_tweet\n",
        "\n",
        "  #use GPT to verify if the tweet is appropriate\n",
        "  input='''you are a professional ESG PR person that responds to other KOLs tweets, you will first have to assess whether the following\n",
        "           tweet is appropriate to respond to. you will respond to any tweets that have something to do with ESG developments in the broad sense.\n",
        "           You will not respond to personal statements like 'Im going to LA, let me know if you are there' or 'happy birthday to my little kid'. \n",
        "           is the following tweet appropriate or not? reply with yes or no, nothing else, do not add a period behind the output'''+ latest_tweet\n",
        "\n",
        "  completion = openai.ChatCompletion.create(\n",
        "      model=\"gpt-3.5-turbo\", \n",
        "      messages=[{\"role\": \"user\", \"content\": input}]\n",
        "  )\n",
        "  json_object = json.loads(str(completion))\n",
        "  output = json_object['choices'][0]['message']['content']\n",
        "  output = json_object['choices'][0]['message']['content'].lower().strip() #get rid of variations in the answer\n",
        "  print(output)\n",
        "\n",
        "#________________________________________________________________________________________\n",
        "\n",
        "#big if statement, if tweet is a proper tweet to respond to \n",
        "  if output == 'yes':\n",
        "    #create response\n",
        "    input='you are feeling really'+ mood +'Generate a short tweet that responds to the following tweet, tag the original poster in your response, do not just simply rephrase the post but add a personal opinion.'  + latest_tweet\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "      model=\"gpt-3.5-turbo\", \n",
        "      messages=[{\"role\": \"user\", \"content\": input}]\n",
        "    )\n",
        "    json_object = json.loads(str(completion))\n",
        "    output = json_object['choices'][0]['message']['content']\n",
        "    # print(output)\n",
        "    \n",
        "    # get link \n",
        "    tweet_id = tweet_id # replace with the tweet ID you want to get the link from\n",
        "    screen_name = username # replace with the screen name of the user who posted the tweet\n",
        "\n",
        "    tweet_link = f\"https://twitter.com/{screen_name}/status/{tweet_id}\"\n",
        "\n",
        "    # print(tweet_link)\n",
        "\n",
        "    #gpt4 api? or not necessary?\n",
        "    output='.'+output+' '+ tweet_link\n",
        "    output\n",
        "\n",
        "    tweet = api.update_status(output)\n",
        "    print(f\"Tweeted: {tweet.text}\")\n",
        "\n",
        "  #if this is not an appropriate tweet to respond to, restart the process  \n",
        "  elif output == 'no':\n",
        "        process_tweet()\n",
        "  else:\n",
        "        process_tweet()\n",
        "process_tweet()\n",
        "\n",
        "#end of process_tweet() function\n",
        "#________________________________________________________________________________________\n",
        "\n",
        "#start scheduler function! We want it to post twice per day\n",
        "def run_scheduler():\n",
        "    # Clear out existing schedule (optional)\n",
        "    schedule.clear()\n",
        "\n",
        "    # Define the times you want to run the job\n",
        "    morning_hours = list(range(6, 12))  # 6AM - 11AM\n",
        "    afternoon_hours = list(range(12, 18))  # 12PM - 5PM\n",
        "\n",
        "    # Select a random hour in the morning and afternoon\n",
        "    morning_hour = random.choice(morning_hours)\n",
        "    afternoon_hour = random.choice(afternoon_hours)\n",
        "\n",
        "    # Define a random minute\n",
        "    minute = random.randint(0, 59)\n",
        "\n",
        "    # Schedule the job for these times\n",
        "    schedule.every().day.at(f\"{morning_hour:02d}:{minute:02d}\").do(process_tweet)\n",
        "    schedule.every().day.at(f\"{afternoon_hour:02d}:{minute:02d}\").do(process_tweet)\n",
        "\n",
        "    # Keep the script running\n",
        "    while True:\n",
        "        schedule.run_pending()\n",
        "        time.sleep(10)\n",
        "\n",
        "run_scheduler()\n",
        "\n"
      ]
    }
  ]
}